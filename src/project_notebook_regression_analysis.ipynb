{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import all the modules you will need in this notebook here:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# exercise 0\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt \n",
    "\n",
    "import statsmodels\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "\n",
    "# Seaborn for easier visualization \n",
    "from statsmodels.graphics.regressionplots import abline_plot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We continue analysing the `fram` heart disease data.\n",
    "\n",
    "First load the data, use the name `fram` for the DataFrame variable. Make sure that in the data you loaded the column and row headers are in place. Checkout the summary of the variables using the `describe` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                ID          AGE          FRW          SBP       SBP10  \\\n",
       "count  1394.000000  1394.000000  1394.000000  1394.000000  767.000000   \n",
       "mean   4737.184362    52.431133   105.365136   148.086083  148.040417   \n",
       "std    1073.406896     4.781507    17.752489    28.022062   25.706664   \n",
       "min    1070.000000    45.000000    52.000000    90.000000   94.000000   \n",
       "25%    3890.250000    48.000000    94.000000   130.000000  130.000000   \n",
       "50%    4821.000000    52.000000   103.000000   142.000000  145.000000   \n",
       "75%    5641.750000    56.000000   114.000000   160.000000  160.000000   \n",
       "max    6442.000000    62.000000   222.000000   300.000000  264.000000   \n",
       "\n",
       "               DBP         CHOL          CIG          CHD        DEATH  \\\n",
       "count  1394.000000  1394.000000  1394.000000  1394.000000  1394.000000   \n",
       "mean     90.135581   234.644907     8.029412     1.187948     1.700861   \n",
       "std      14.226235    46.303822    11.584138     2.615976     3.203132   \n",
       "min      50.000000    96.000000     0.000000     0.000000     0.000000   \n",
       "25%      80.000000   200.000000     0.000000     0.000000     0.000000   \n",
       "50%      90.000000   230.000000     0.000000     0.000000     0.000000   \n",
       "75%      98.000000   264.000000    20.000000     0.000000     0.000000   \n",
       "max     160.000000   430.000000    60.000000    10.000000    10.000000   \n",
       "\n",
       "           YRS_DTH  \n",
       "count  1394.000000  \n",
       "mean     16.219512  \n",
       "std       3.921413  \n",
       "min       1.000000  \n",
       "25%      18.000000  \n",
       "50%      18.000000  \n",
       "75%      18.000000  \n",
       "max      18.000000  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>ID</th>\n      <th>AGE</th>\n      <th>FRW</th>\n      <th>SBP</th>\n      <th>SBP10</th>\n      <th>DBP</th>\n      <th>CHOL</th>\n      <th>CIG</th>\n      <th>CHD</th>\n      <th>DEATH</th>\n      <th>YRS_DTH</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>count</th>\n      <td>1394.000000</td>\n      <td>1394.000000</td>\n      <td>1394.000000</td>\n      <td>1394.000000</td>\n      <td>767.000000</td>\n      <td>1394.000000</td>\n      <td>1394.000000</td>\n      <td>1394.000000</td>\n      <td>1394.000000</td>\n      <td>1394.000000</td>\n      <td>1394.000000</td>\n    </tr>\n    <tr>\n      <th>mean</th>\n      <td>4737.184362</td>\n      <td>52.431133</td>\n      <td>105.365136</td>\n      <td>148.086083</td>\n      <td>148.040417</td>\n      <td>90.135581</td>\n      <td>234.644907</td>\n      <td>8.029412</td>\n      <td>1.187948</td>\n      <td>1.700861</td>\n      <td>16.219512</td>\n    </tr>\n    <tr>\n      <th>std</th>\n      <td>1073.406896</td>\n      <td>4.781507</td>\n      <td>17.752489</td>\n      <td>28.022062</td>\n      <td>25.706664</td>\n      <td>14.226235</td>\n      <td>46.303822</td>\n      <td>11.584138</td>\n      <td>2.615976</td>\n      <td>3.203132</td>\n      <td>3.921413</td>\n    </tr>\n    <tr>\n      <th>min</th>\n      <td>1070.000000</td>\n      <td>45.000000</td>\n      <td>52.000000</td>\n      <td>90.000000</td>\n      <td>94.000000</td>\n      <td>50.000000</td>\n      <td>96.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>1.000000</td>\n    </tr>\n    <tr>\n      <th>25%</th>\n      <td>3890.250000</td>\n      <td>48.000000</td>\n      <td>94.000000</td>\n      <td>130.000000</td>\n      <td>130.000000</td>\n      <td>80.000000</td>\n      <td>200.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>18.000000</td>\n    </tr>\n    <tr>\n      <th>50%</th>\n      <td>4821.000000</td>\n      <td>52.000000</td>\n      <td>103.000000</td>\n      <td>142.000000</td>\n      <td>145.000000</td>\n      <td>90.000000</td>\n      <td>230.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>18.000000</td>\n    </tr>\n    <tr>\n      <th>75%</th>\n      <td>5641.750000</td>\n      <td>56.000000</td>\n      <td>114.000000</td>\n      <td>160.000000</td>\n      <td>160.000000</td>\n      <td>98.000000</td>\n      <td>264.000000</td>\n      <td>20.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>18.000000</td>\n    </tr>\n    <tr>\n      <th>max</th>\n      <td>6442.000000</td>\n      <td>62.000000</td>\n      <td>222.000000</td>\n      <td>300.000000</td>\n      <td>264.000000</td>\n      <td>160.000000</td>\n      <td>430.000000</td>\n      <td>60.000000</td>\n      <td>10.000000</td>\n      <td>10.000000</td>\n      <td>18.000000</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 37
    }
   ],
   "source": [
    "# exercise 1\n",
    "\n",
    "def get_path(filename):\n",
    "    import sys\n",
    "    import os\n",
    "    prog_name = sys.argv[0]\n",
    "    if os.path.basename(prog_name) == \"__main__.py\":   # Running under TMC\n",
    "        return os.path.join(os.path.dirname(prog_name), \"..\", \"src\", filename)\n",
    "    else:\n",
    "        return filename\n",
    "    \n",
    "# Put your solution here!\n",
    "# My solution reads the path directly into a Path() object\n",
    "filename = get_path(\"fram.txt\")\n",
    "\n",
    "fram = pd.read_csv(filename, sep=\"\\t\")\n",
    "\n",
    "# Head of the new dataframe\n",
    "fram.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create function `rescale` that takes a Series as parameter. It should center the data and normalize it by dividing\n",
    "by 2$\\sigma$, where $\\sigma$ is the standard deviation. Return the rescaled Series."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# exercise 2\n",
    "def rescale(series):\n",
    "    return (series - series.mean()) / (2 * series.std())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add to the DataFrame the scaled versions of all the continuous variables (with function `rescale`). Add small letter `s` in front of the original variable name to get the name of the scaled variable. For instance, `AGE` -> `sAGE`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "sID\nsAGE\nsFRW\nsSBP\nsSBP10\nsDBP\nsCHOL\nsCIG\nsCHD\nsDEATH\nsYRS_DTH\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "     ID     SEX  AGE  FRW  SBP  SBP10  DBP  CHOL  CIG  CHD  ...      sAGE  \\\n0  4988  female   57  135  186    NaN  120   150    0    1  ...  0.477764   \n1  3001  female   60  123  165    NaN  100   167   25    0  ...  0.791473   \n2  5079  female   54  115  140    NaN   90   213    5    0  ...  0.164056   \n3  5162  female   52  102  170    NaN  104   280   15    0  ... -0.045083   \n4  4672  female   45   99  185    NaN  105   326   20    0  ... -0.777070   \n\n       sFRW      sSBP sSBP10      sDBP     sCHOL      sCIG      sCHD  \\\n0  0.834668  0.676501    NaN  1.049625 -0.914016 -0.346569 -0.035923   \n1  0.496687  0.301796    NaN  0.346698 -0.730446  0.732493 -0.227056   \n2  0.271367 -0.144281    NaN -0.004765 -0.233727 -0.130757 -0.227056   \n3 -0.094779  0.391012    NaN  0.487283  0.489755  0.300868 -0.227056   \n4 -0.179274  0.658658    NaN  0.522430  0.986475  0.516680 -0.227056   \n\n     sDEATH  sYRS_DTH  \n0  0.827181 -0.665514  \n1  1.295472  0.099516  \n2  0.983278 -0.410504  \n3  0.827181 -0.665514  \n4  1.295472  0.099516  \n\n[5 rows x 25 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>ID</th>\n      <th>SEX</th>\n      <th>AGE</th>\n      <th>FRW</th>\n      <th>SBP</th>\n      <th>SBP10</th>\n      <th>DBP</th>\n      <th>CHOL</th>\n      <th>CIG</th>\n      <th>CHD</th>\n      <th>...</th>\n      <th>sAGE</th>\n      <th>sFRW</th>\n      <th>sSBP</th>\n      <th>sSBP10</th>\n      <th>sDBP</th>\n      <th>sCHOL</th>\n      <th>sCIG</th>\n      <th>sCHD</th>\n      <th>sDEATH</th>\n      <th>sYRS_DTH</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>4988</td>\n      <td>female</td>\n      <td>57</td>\n      <td>135</td>\n      <td>186</td>\n      <td>NaN</td>\n      <td>120</td>\n      <td>150</td>\n      <td>0</td>\n      <td>1</td>\n      <td>...</td>\n      <td>0.477764</td>\n      <td>0.834668</td>\n      <td>0.676501</td>\n      <td>NaN</td>\n      <td>1.049625</td>\n      <td>-0.914016</td>\n      <td>-0.346569</td>\n      <td>-0.035923</td>\n      <td>0.827181</td>\n      <td>-0.665514</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>3001</td>\n      <td>female</td>\n      <td>60</td>\n      <td>123</td>\n      <td>165</td>\n      <td>NaN</td>\n      <td>100</td>\n      <td>167</td>\n      <td>25</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0.791473</td>\n      <td>0.496687</td>\n      <td>0.301796</td>\n      <td>NaN</td>\n      <td>0.346698</td>\n      <td>-0.730446</td>\n      <td>0.732493</td>\n      <td>-0.227056</td>\n      <td>1.295472</td>\n      <td>0.099516</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>5079</td>\n      <td>female</td>\n      <td>54</td>\n      <td>115</td>\n      <td>140</td>\n      <td>NaN</td>\n      <td>90</td>\n      <td>213</td>\n      <td>5</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0.164056</td>\n      <td>0.271367</td>\n      <td>-0.144281</td>\n      <td>NaN</td>\n      <td>-0.004765</td>\n      <td>-0.233727</td>\n      <td>-0.130757</td>\n      <td>-0.227056</td>\n      <td>0.983278</td>\n      <td>-0.410504</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>5162</td>\n      <td>female</td>\n      <td>52</td>\n      <td>102</td>\n      <td>170</td>\n      <td>NaN</td>\n      <td>104</td>\n      <td>280</td>\n      <td>15</td>\n      <td>0</td>\n      <td>...</td>\n      <td>-0.045083</td>\n      <td>-0.094779</td>\n      <td>0.391012</td>\n      <td>NaN</td>\n      <td>0.487283</td>\n      <td>0.489755</td>\n      <td>0.300868</td>\n      <td>-0.227056</td>\n      <td>0.827181</td>\n      <td>-0.665514</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>4672</td>\n      <td>female</td>\n      <td>45</td>\n      <td>99</td>\n      <td>185</td>\n      <td>NaN</td>\n      <td>105</td>\n      <td>326</td>\n      <td>20</td>\n      <td>0</td>\n      <td>...</td>\n      <td>-0.777070</td>\n      <td>-0.179274</td>\n      <td>0.658658</td>\n      <td>NaN</td>\n      <td>0.522430</td>\n      <td>0.986475</td>\n      <td>0.516680</td>\n      <td>-0.227056</td>\n      <td>1.295472</td>\n      <td>0.099516</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows Ã— 25 columns</p>\n</div>"
     },
     "metadata": {}
    }
   ],
   "source": [
    "# exercise 3\n",
    "numeric_columns = fram.select_dtypes(np.number).columns\n",
    "for col in numeric_columns:\n",
    "    print(\"s\" + col)\n",
    "    fram[\"s\" + col] = rescale(fram[col])\n",
    "display(fram.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Form a model that predicts systolic blood pressure using weight, gender, and cholesterol level as explanatory variables. Store the fitted model in variable named `fit`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<class 'statsmodels.iolib.summary.Summary'>\n\"\"\"\n                            OLS Regression Results                            \n==============================================================================\nDep. Variable:                    SBP   R-squared:                       0.125\nModel:                            OLS   Adj. R-squared:                  0.123\nMethod:                 Least Squares   F-statistic:                     66.37\nDate:                Fri, 25 Dec 2020   Prob (F-statistic):           4.13e-40\nTime:                        19:12:37   Log-Likelihood:                -6530.4\nNo. Observations:                1394   AIC:                         1.307e+04\nDf Residuals:                    1390   BIC:                         1.309e+04\nDf Model:                           3                                         \nCovariance Type:            nonrobust                                         \n===============================================================================\n                  coef    std err          t      P>|t|      [0.025      0.975]\n-------------------------------------------------------------------------------\nIntercept     150.0199      0.985    152.336      0.000     148.088     151.952\nSEX[T.male]    -4.0659      1.451     -2.803      0.005      -6.912      -1.220\nsFRW           17.7205      1.426     12.431      0.000      14.924      20.517\nsCHOL           4.9169      1.431      3.436      0.001       2.110       7.724\n==============================================================================\nOmnibus:                      327.612   Durbin-Watson:                   1.774\nProb(Omnibus):                  0.000   Jarque-Bera (JB):              843.676\nSkew:                           1.237   Prob(JB):                    6.28e-184\nKurtosis:                       5.899   Cond. No.                         2.79\n==============================================================================\n\nNotes:\n[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n\"\"\"",
      "text/html": "<table class=\"simpletable\">\n<caption>OLS Regression Results</caption>\n<tr>\n  <th>Dep. Variable:</th>           <td>SBP</td>       <th>  R-squared:         </th> <td>   0.125</td> \n</tr>\n<tr>\n  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.123</td> \n</tr>\n<tr>\n  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   66.37</td> \n</tr>\n<tr>\n  <th>Date:</th>             <td>Fri, 25 Dec 2020</td> <th>  Prob (F-statistic):</th> <td>4.13e-40</td> \n</tr>\n<tr>\n  <th>Time:</th>                 <td>19:12:37</td>     <th>  Log-Likelihood:    </th> <td> -6530.4</td> \n</tr>\n<tr>\n  <th>No. Observations:</th>      <td>  1394</td>      <th>  AIC:               </th> <td>1.307e+04</td>\n</tr>\n<tr>\n  <th>Df Residuals:</th>          <td>  1390</td>      <th>  BIC:               </th> <td>1.309e+04</td>\n</tr>\n<tr>\n  <th>Df Model:</th>              <td>     3</td>      <th>                     </th>     <td> </td>    \n</tr>\n<tr>\n  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>    \n</tr>\n</table>\n<table class=\"simpletable\">\n<tr>\n       <td></td>          <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n</tr>\n<tr>\n  <th>Intercept</th>   <td>  150.0199</td> <td>    0.985</td> <td>  152.336</td> <td> 0.000</td> <td>  148.088</td> <td>  151.952</td>\n</tr>\n<tr>\n  <th>SEX[T.male]</th> <td>   -4.0659</td> <td>    1.451</td> <td>   -2.803</td> <td> 0.005</td> <td>   -6.912</td> <td>   -1.220</td>\n</tr>\n<tr>\n  <th>sFRW</th>        <td>   17.7205</td> <td>    1.426</td> <td>   12.431</td> <td> 0.000</td> <td>   14.924</td> <td>   20.517</td>\n</tr>\n<tr>\n  <th>sCHOL</th>       <td>    4.9169</td> <td>    1.431</td> <td>    3.436</td> <td> 0.001</td> <td>    2.110</td> <td>    7.724</td>\n</tr>\n</table>\n<table class=\"simpletable\">\n<tr>\n  <th>Omnibus:</th>       <td>327.612</td> <th>  Durbin-Watson:     </th> <td>   1.774</td> \n</tr>\n<tr>\n  <th>Prob(Omnibus):</th> <td> 0.000</td>  <th>  Jarque-Bera (JB):  </th> <td> 843.676</td> \n</tr>\n<tr>\n  <th>Skew:</th>          <td> 1.237</td>  <th>  Prob(JB):          </th> <td>6.28e-184</td>\n</tr>\n<tr>\n  <th>Kurtosis:</th>      <td> 5.899</td>  <th>  Cond. No.          </th> <td>    2.79</td> \n</tr>\n</table><br/><br/>Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified."
     },
     "metadata": {}
    }
   ],
   "source": [
    "# exercise 4\n",
    "fit = smf.ols(\"SBP ~ sFRW + sCHOL + SEX\", data=fram).fit()\n",
    "display(fit.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add the variable AGE to the model and inspect the estimates of the coefficients using the `summary` method of the fitted model. Again use the name `fit` for the fitted model. (From now on assume that we always use the name `fit` for the variable of the fitted model.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<class 'statsmodels.iolib.summary.Summary'>\n\"\"\"\n                            OLS Regression Results                            \n==============================================================================\nDep. Variable:                    SBP   R-squared:                       0.146\nModel:                            OLS   Adj. R-squared:                  0.144\nMethod:                 Least Squares   F-statistic:                     59.39\nDate:                Fri, 25 Dec 2020   Prob (F-statistic):           2.44e-46\nTime:                        19:12:49   Log-Likelihood:                -6513.6\nNo. Observations:                1394   AIC:                         1.304e+04\nDf Residuals:                    1389   BIC:                         1.306e+04\nDf Model:                           4                                         \nCovariance Type:            nonrobust                                         \n===============================================================================\n                  coef    std err          t      P>|t|      [0.025      0.975]\n-------------------------------------------------------------------------------\nIntercept     150.1695      0.974    154.221      0.000     148.259     152.080\nSEX[T.male]    -4.3805      1.435     -3.053      0.002      -7.195      -1.566\nsFRW           16.9771      1.415     11.999      0.000      14.202      19.753\nsCHOL           4.2696      1.419      3.009      0.003       1.486       7.053\nsAGE            8.1332      1.400      5.810      0.000       5.387      10.879\n==============================================================================\nOmnibus:                      321.087   Durbin-Watson:                   1.807\nProb(Omnibus):                  0.000   Jarque-Bera (JB):              840.955\nSkew:                           1.206   Prob(JB):                    2.45e-183\nKurtosis:                       5.944   Cond. No.                         2.82\n==============================================================================\n\nNotes:\n[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n\"\"\"",
      "text/html": "<table class=\"simpletable\">\n<caption>OLS Regression Results</caption>\n<tr>\n  <th>Dep. Variable:</th>           <td>SBP</td>       <th>  R-squared:         </th> <td>   0.146</td> \n</tr>\n<tr>\n  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.144</td> \n</tr>\n<tr>\n  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   59.39</td> \n</tr>\n<tr>\n  <th>Date:</th>             <td>Fri, 25 Dec 2020</td> <th>  Prob (F-statistic):</th> <td>2.44e-46</td> \n</tr>\n<tr>\n  <th>Time:</th>                 <td>19:12:49</td>     <th>  Log-Likelihood:    </th> <td> -6513.6</td> \n</tr>\n<tr>\n  <th>No. Observations:</th>      <td>  1394</td>      <th>  AIC:               </th> <td>1.304e+04</td>\n</tr>\n<tr>\n  <th>Df Residuals:</th>          <td>  1389</td>      <th>  BIC:               </th> <td>1.306e+04</td>\n</tr>\n<tr>\n  <th>Df Model:</th>              <td>     4</td>      <th>                     </th>     <td> </td>    \n</tr>\n<tr>\n  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>    \n</tr>\n</table>\n<table class=\"simpletable\">\n<tr>\n       <td></td>          <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n</tr>\n<tr>\n  <th>Intercept</th>   <td>  150.1695</td> <td>    0.974</td> <td>  154.221</td> <td> 0.000</td> <td>  148.259</td> <td>  152.080</td>\n</tr>\n<tr>\n  <th>SEX[T.male]</th> <td>   -4.3805</td> <td>    1.435</td> <td>   -3.053</td> <td> 0.002</td> <td>   -7.195</td> <td>   -1.566</td>\n</tr>\n<tr>\n  <th>sFRW</th>        <td>   16.9771</td> <td>    1.415</td> <td>   11.999</td> <td> 0.000</td> <td>   14.202</td> <td>   19.753</td>\n</tr>\n<tr>\n  <th>sCHOL</th>       <td>    4.2696</td> <td>    1.419</td> <td>    3.009</td> <td> 0.003</td> <td>    1.486</td> <td>    7.053</td>\n</tr>\n<tr>\n  <th>sAGE</th>        <td>    8.1332</td> <td>    1.400</td> <td>    5.810</td> <td> 0.000</td> <td>    5.387</td> <td>   10.879</td>\n</tr>\n</table>\n<table class=\"simpletable\">\n<tr>\n  <th>Omnibus:</th>       <td>321.087</td> <th>  Durbin-Watson:     </th> <td>   1.807</td> \n</tr>\n<tr>\n  <th>Prob(Omnibus):</th> <td> 0.000</td>  <th>  Jarque-Bera (JB):  </th> <td> 840.955</td> \n</tr>\n<tr>\n  <th>Skew:</th>          <td> 1.206</td>  <th>  Prob(JB):          </th> <td>2.45e-183</td>\n</tr>\n<tr>\n  <th>Kurtosis:</th>      <td> 5.944</td>  <th>  Cond. No.          </th> <td>    2.82</td> \n</tr>\n</table><br/><br/>Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified."
     },
     "metadata": {}
    }
   ],
   "source": [
    "# exercise 5\n",
    "fit = smf.ols(\"SBP ~ sFRW + sCHOL + SEX + sAGE\", data=fram).fit()\n",
    "display(fit.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How much does the inclusion of age increase the explanatory power of the model? Which variables explain the variance of the target variable most?\n",
    "\n",
    "***\n",
    "\n",
    "The inclusion of `sAge` increases the R<sup>2</sup> by an amount equals to ~ 0.2, therefore the explanatory power is not that much better than before.\n",
    "\n",
    "The `sFRW` parameter (normalized weight) does explain the variance the most, as it is the one with the greatest (in magnitude) coefficient.\n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try to add to the model all the interactions with other variables. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<class 'statsmodels.iolib.summary.Summary'>\n\"\"\"\n                            OLS Regression Results                            \n==============================================================================\nDep. Variable:                    SBP   R-squared:                       0.709\nModel:                            OLS   Adj. R-squared:                  0.705\nMethod:                 Least Squares   F-statistic:                     230.3\nDate:                Fri, 25 Dec 2020   Prob (F-statistic):          4.03e-197\nTime:                        19:18:48   Log-Likelihood:                -3118.5\nNo. Observations:                 767   AIC:                             6255.\nDf Residuals:                     758   BIC:                             6297.\nDf Model:                           8                                         \nCovariance Type:            nonrobust                                         \n===============================================================================\n                  coef    std err          t      P>|t|      [0.025      0.975]\n-------------------------------------------------------------------------------\nIntercept     141.2036      0.718    196.746      0.000     139.795     142.613\nSEX[T.male]    -4.8611      1.165     -4.171      0.000      -7.149      -2.573\nsFRW            1.6048      1.180      1.361      0.174      -0.711       3.920\nsCHOL          -0.5160      1.065     -0.485      0.628      -2.606       1.574\nsAGE            5.0781      1.111      4.570      0.000       2.897       7.259\nsCIG           -0.2266      1.240     -0.183      0.855      -2.661       2.207\nsSBP10         11.6729      1.143     10.208      0.000       9.428      13.918\nsDBP           38.4216      1.291     29.772      0.000      35.888      40.955\nsCHD            2.6466      1.051      2.519      0.012       0.584       4.709\nsYRS_DTH       32.0562      0.163    196.746      0.000      31.736      32.376\n==============================================================================\nOmnibus:                      118.712   Durbin-Watson:                   1.909\nProb(Omnibus):                  0.000   Jarque-Bera (JB):              246.310\nSkew:                           0.881   Prob(JB):                     3.27e-54\nKurtosis:                       5.145   Cond. No.                     1.06e+16\n==============================================================================\n\nNotes:\n[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n[2] The smallest eigenvalue is 8.8e-30. This might indicate that there are\nstrong multicollinearity problems or that the design matrix is singular.\n\"\"\"",
      "text/html": "<table class=\"simpletable\">\n<caption>OLS Regression Results</caption>\n<tr>\n  <th>Dep. Variable:</th>           <td>SBP</td>       <th>  R-squared:         </th> <td>   0.709</td> \n</tr>\n<tr>\n  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.705</td> \n</tr>\n<tr>\n  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   230.3</td> \n</tr>\n<tr>\n  <th>Date:</th>             <td>Fri, 25 Dec 2020</td> <th>  Prob (F-statistic):</th> <td>4.03e-197</td>\n</tr>\n<tr>\n  <th>Time:</th>                 <td>19:18:48</td>     <th>  Log-Likelihood:    </th> <td> -3118.5</td> \n</tr>\n<tr>\n  <th>No. Observations:</th>      <td>   767</td>      <th>  AIC:               </th> <td>   6255.</td> \n</tr>\n<tr>\n  <th>Df Residuals:</th>          <td>   758</td>      <th>  BIC:               </th> <td>   6297.</td> \n</tr>\n<tr>\n  <th>Df Model:</th>              <td>     8</td>      <th>                     </th>     <td> </td>    \n</tr>\n<tr>\n  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>    \n</tr>\n</table>\n<table class=\"simpletable\">\n<tr>\n       <td></td>          <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n</tr>\n<tr>\n  <th>Intercept</th>   <td>  141.2036</td> <td>    0.718</td> <td>  196.746</td> <td> 0.000</td> <td>  139.795</td> <td>  142.613</td>\n</tr>\n<tr>\n  <th>SEX[T.male]</th> <td>   -4.8611</td> <td>    1.165</td> <td>   -4.171</td> <td> 0.000</td> <td>   -7.149</td> <td>   -2.573</td>\n</tr>\n<tr>\n  <th>sFRW</th>        <td>    1.6048</td> <td>    1.180</td> <td>    1.361</td> <td> 0.174</td> <td>   -0.711</td> <td>    3.920</td>\n</tr>\n<tr>\n  <th>sCHOL</th>       <td>   -0.5160</td> <td>    1.065</td> <td>   -0.485</td> <td> 0.628</td> <td>   -2.606</td> <td>    1.574</td>\n</tr>\n<tr>\n  <th>sAGE</th>        <td>    5.0781</td> <td>    1.111</td> <td>    4.570</td> <td> 0.000</td> <td>    2.897</td> <td>    7.259</td>\n</tr>\n<tr>\n  <th>sCIG</th>        <td>   -0.2266</td> <td>    1.240</td> <td>   -0.183</td> <td> 0.855</td> <td>   -2.661</td> <td>    2.207</td>\n</tr>\n<tr>\n  <th>sSBP10</th>      <td>   11.6729</td> <td>    1.143</td> <td>   10.208</td> <td> 0.000</td> <td>    9.428</td> <td>   13.918</td>\n</tr>\n<tr>\n  <th>sDBP</th>        <td>   38.4216</td> <td>    1.291</td> <td>   29.772</td> <td> 0.000</td> <td>   35.888</td> <td>   40.955</td>\n</tr>\n<tr>\n  <th>sCHD</th>        <td>    2.6466</td> <td>    1.051</td> <td>    2.519</td> <td> 0.012</td> <td>    0.584</td> <td>    4.709</td>\n</tr>\n<tr>\n  <th>sYRS_DTH</th>    <td>   32.0562</td> <td>    0.163</td> <td>  196.746</td> <td> 0.000</td> <td>   31.736</td> <td>   32.376</td>\n</tr>\n</table>\n<table class=\"simpletable\">\n<tr>\n  <th>Omnibus:</th>       <td>118.712</td> <th>  Durbin-Watson:     </th> <td>   1.909</td>\n</tr>\n<tr>\n  <th>Prob(Omnibus):</th> <td> 0.000</td>  <th>  Jarque-Bera (JB):  </th> <td> 246.310</td>\n</tr>\n<tr>\n  <th>Skew:</th>          <td> 0.881</td>  <th>  Prob(JB):          </th> <td>3.27e-54</td>\n</tr>\n<tr>\n  <th>Kurtosis:</th>      <td> 5.145</td>  <th>  Cond. No.          </th> <td>1.06e+16</td>\n</tr>\n</table><br/><br/>Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.<br/>[2] The smallest eigenvalue is 8.8e-30. This might indicate that there are<br/>strong multicollinearity problems or that the design matrix is singular."
     },
     "metadata": {}
    }
   ],
   "source": [
    "# exercise 6\n",
    "fit = smf.ols(\"SBP ~ sFRW + sCHOL + SEX + sAGE + sCIG + sSBP10 + sDBP + sCHD + sYRS_DTH\", data=fram).fit()\n",
    "display(fit.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then visualize the model as the function of weight for the youngest (sAGE=-1.0), middle aged (sAGE=0.0), and oldest (sAGE=1.0) women while assuming the background variables to be centered. Remember to consider the changes in the intercept and in the regression coefficient caused by age. Visualize both the data points and the fitted lines."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# exercise 7\n",
    "# TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How does the dependence of blood pressure on weight change as a person gets older?\n",
    "***\n",
    "\n",
    "Your solution here.\n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Even more accurate model\n",
    "\n",
    "Include the background variable `sCIG` from the data and its interactions. Visualize the model for systolic blood pressure as the function of the most important explanatory variable. Visualize separate lines for the small (-1.0), average (0.0), and large (1.0) values of `sCHOL`. Other variables can be assumed to be at their mean value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# exercise 8\n",
    "# Put your solution here!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How does the model and its accuracy look?\n",
    "\n",
    "***\n",
    "\n",
    "Your solution here.\n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def logistic(x):\n",
    "    return 1.0 / (1.0 + np.exp(-x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will continue predicting high blood pressure by taking in some continuous background variables, such as the age."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recreate the model `HIGH_BP ~ sFRW + SEX + SEX:sFRW` presented in the introduction. Make sure, that you get the same results. Use name `fit` for the fitted model. Compute and store the error rate into variable `error_rate_orig`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# exercise 9\n",
    "# Put your solution here!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add the `sAGE` variable and its interactions. Check the prediction accuracy of the model and compare it to the previous model. Store the prediction accuracy to variable `error_rate`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# exercise 10\n",
    "# Put your solution here!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualize the predicted probability of high blood pressure as the function of weight. Remember to use normalized values (`rescale`) also for those variables that are not included in the visualization, so that sensible values are used for them (data average). Draw two figures with altogether six curves: young, middle aged, and old women; and young, middle aged, and old men. Use `plt.subplots`. (Plotting works in similar fashion as in the introduction. The argument factors need, however, be changed as in the example about visualisation of continuous variable.) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# exercise 11\n",
    "\n",
    "def logistic(x):\n",
    "    return 1.0 / (1.0 + np.exp(-x))\n",
    "\n",
    "# Put your solution here!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How do the models with different ages and genders differ from each other?\n",
    "\n",
    "***\n",
    "Your solution here.\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create here a helper function `train_test_split` that gets a DataFrame as parameter and return a pair of DataFrames: one for training and the second for testing. \n",
    "The function should get parameters in the following way:\n",
    "```python\n",
    "train_test_split(df, train_fraction=0.8)\n",
    "```\n",
    "The data should be split randomly to training and testing DataFrames so that `train_fraction` fraction of data should go into the training set. Use the `sample` method of the DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# exercise 12\n",
    "# Put your solution here!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check the prediction accuracy of your model using cross validation. Use 100-fold cross validation and training_fraction 0.8."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# exercise 13\n",
    "np.random.seed(1)\n",
    "# Put your solution here!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predicting coronary heart disease\n",
    "\n",
    "Let us use again the same data to learn a model for the occurrence of coronary heart disease. We will use logistic regression to predict whether a patient *sometimes* shows symptoms of coronary heart disease. For this, add to the data a binary variable `hasCHD`, that describes the event (`CHD > 0`). The binary variable `hadCHD` can get only two values: 0 or 1. As a sanity check, compute the mean of this variable, which tells the number of positive cases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# exercise 14\n",
    "# Put your solution here!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, form a logistic regression model for variable `hasCHD` by using variables sCHOL, sCIG, and sFRW, and their interactions as explanatory variables. Store the fitted model to variable `fit`. Compute the prediction accuracy of the model, store it to variable `error_rate`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# exercise 15\n",
    "# Put your solution here!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualize the model by using the most important explanator on the x axis. Visualize both the points (with `plt.scatter`)\n",
    "and the logistic curve (with `plt.plot`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# exercise 16\n",
    "def logistic(x):\n",
    "    return 1.0 / (1.0 + np.exp(-x))\n",
    "# Put your solution here!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Is the prediction accuracy of the model good or bad? Can we expect to have practical use of the model?\n",
    "***\n",
    "Your solution here.\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If a person has cholestherol 200, smokes 17 cigarets per day, and has weight 100, then what is the probability that he/she sometimes shows signs of coronal hear disease? Note that the model expects normalized values. Store the normalized values to dictionary called `point`. Store the probability in variable `predicted`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# exercise 17\n",
    "# Put your solution here!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}